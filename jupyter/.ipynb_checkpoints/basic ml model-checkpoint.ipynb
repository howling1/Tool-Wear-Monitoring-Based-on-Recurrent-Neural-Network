{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "from scipy.fftpack import fft, fftshift, ifft\n",
    "from scipy.fftpack import fftfreq\n",
    "import pywt\n",
    "import pywt.data \n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score,classification_report,precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data \n",
    "gtrain_data = pd.read_csv('../data/generative training data.csv')\n",
    "gtest_data = pd.read_csv('../data/generative test data.csv')\n",
    "gvalid_data = pd.read_csv('../data/generative valid data.csv')\n",
    "gtest_data = pd.concat((gtest_data,gvalid_data))\n",
    "gtrain_x = np.array(gtrain_data)[:,:-1] \n",
    "gtrain_y = gtrain_data.iloc[:,-1]\n",
    "gtest_x = np.array(gtest_data)[:,:-1]\n",
    "gtest_y = gtest_data.iloc[:,-1]\n",
    "\n",
    "\n",
    "otrain_data = pd.read_csv('../data/original training data.csv')\n",
    "otest_data = pd.read_csv('../data/original test data.csv')\n",
    "ovalid_data = pd.read_csv('../data/original valid data.csv')\n",
    "otest_data = pd.concat((otest_data,ovalid_data))\n",
    "otrain_x = np.array(otrain_data)[:,:-1] \n",
    "otrain_y = otrain_data.iloc[:,-1]\n",
    "otest_x = np.array(otest_data)[:,:-1]\n",
    "otest_y = otest_data.iloc[:,-1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_feature_extractor(data, sample_point):\n",
    "    \"\"\"Extract time-domain features: mean value, root mean square, waveform factor, clearance factor\"\"\"\n",
    "    means_list, rms_list, waveform_facs_list, clearance_facs_list = [], [], [], []\n",
    "    for i in data:\n",
    "        df_mean = pd.Series(i).mean()\n",
    "        df_rms = math.sqrt(sum([x ** 2 for x in pd.Series(i)]) / sample_point)\n",
    "        df_waveform_fac = df_rms / (abs(pd.Series(i)).mean())\n",
    "        # Sum of squares\n",
    "        sq_sum = 0\n",
    "        for j in range(sample_point):\n",
    "            sq_sum += math.sqrt(abs(i[j]))\n",
    "        df_clearance_fac = (max(pd.Series(i))) / \\\n",
    "            pow((sq_sum / sample_point), 2)\n",
    "\n",
    "        means_list.append(df_mean)\n",
    "        rms_list.append(df_rms)\n",
    "        waveform_facs_list.append(df_waveform_fac)\n",
    "        clearance_facs_list.append(df_clearance_fac)\n",
    "\n",
    "    return means_list, rms_list, waveform_facs_list, clearance_facs_list\n",
    "\n",
    "\n",
    "def get_ps_array(data, num_fft):\n",
    "    \"\"\"Obtain power spectrum\"\"\"\n",
    "    ps_list = []\n",
    "    for i in data:\n",
    "        # FFT\n",
    "        Y = fft(i, num_fft)\n",
    "        Y = np.abs(Y)\n",
    "        # Reduce the DC component by N times, and the chord wave component by N\n",
    "        # / 2 times\n",
    "        Y[0] = Y[0] / num_fft\n",
    "        Y[1:] = Y[1:] / (num_fft / 2)\n",
    "        # power spectrum\n",
    "        ps = Y ** 2 / num_fft\n",
    "        ps = ps[:num_fft // 2]\n",
    "        ps_list.append(ps)\n",
    "    ps_array = np.array(ps_list)\n",
    "    return ps_array\n",
    "\n",
    "\n",
    "def frequency_features_extractor(ps_array, f):\n",
    "    \"\"\"obtain frequency domain features\"\"\"\n",
    "    msf_list, variance_list = [], []\n",
    "    for i in ps_array:\n",
    "        # Mean square frequency\n",
    "        msf = ((np.sqrt(i) * f).sum()) / (i.sum())\n",
    "        # Power spectrum variance\n",
    "        variance = i.var()\n",
    "\n",
    "        msf_list.append(msf)\n",
    "        variance_list.append(variance)\n",
    "\n",
    "    return msf_list, variance_list\n",
    "\n",
    "\n",
    "def wavelet_alternation(data):\n",
    "    \"\"\"extract wavelet feature\"\"\"\n",
    "    sample_num, sample_dim = data.shape\n",
    "    wp_features = np.zeros((sample_num, 8))\n",
    "    for i in range(sample_num):\n",
    "        single_data = data[i, :]\n",
    "        # Wavelet transform to extract sample features\n",
    "        wp = pywt.WaveletPacket(\n",
    "            single_data,\n",
    "            wavelet='db3',\n",
    "            mode='symmetric',\n",
    "            maxlevel=3)  \n",
    "        # Get the node coefficient of level layer\n",
    "        aaa = wp['aaa'].data\n",
    "        aad = wp['aad'].data\n",
    "        ada = wp['ada'].data\n",
    "        add = wp['add'].data\n",
    "        daa = wp['daa'].data\n",
    "        dad = wp['dad'].data\n",
    "        dda = wp['dda'].data\n",
    "        ddd = wp['ddd'].data\n",
    "        # Get norm of node\n",
    "        ret1 = np.linalg.norm(aaa, ord=None)\n",
    "        ret2 = np.linalg.norm(aad, ord=None)\n",
    "        ret3 = np.linalg.norm(ada, ord=None)\n",
    "        ret4 = np.linalg.norm(add, ord=None)\n",
    "        ret5 = np.linalg.norm(daa, ord=None)\n",
    "        ret6 = np.linalg.norm(dad, ord=None)\n",
    "        ret7 = np.linalg.norm(dda, ord=None)\n",
    "        ret8 = np.linalg.norm(ddd, ord=None)\n",
    "        # obtain 8 nodes combined into eigenvector\n",
    "        single_feature = [ret1, ret2, ret3, ret4, ret5, ret6, ret7, ret8]\n",
    "        wp_features[i][:] = single_feature  # Array\n",
    "\n",
    "    return wp_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_point = 130\n",
    "num_fft = 130 \n",
    "fs = 10\n",
    "df = fs / (num_fft)  # resolving power\n",
    "# create frequency array\n",
    "f = [df * n for n in range(0, num_fft)]\n",
    "f = np.array(f[:num_fft // 2])\n",
    "\n",
    "# obtain time domain feature list\n",
    "gtrain_means_list, gtrain_rms_list, gtrain_waveform_facs_list, gtrain_clearance_facs_list = time_feature_extractor(gtrain_x, sample_point)\n",
    "gtest_means_list, gtest_rms_list, gtest_waveform_facs_list, gtest_clearance_facs_list = time_feature_extractor(gtest_x, sample_point)\n",
    "\n",
    "otrain_means_list, otrain_rms_list, otrain_waveform_facs_list, otrain_clearance_facs_list = time_feature_extractor(otrain_x, sample_point)\n",
    "otest_means_list, otest_rms_list, otest_waveform_facs_list, otest_clearance_facs_list = time_feature_extractor(otest_x, sample_point)\n",
    "\n",
    "# obtain frequency features\n",
    "gtrain_ps = get_ps_array(gtrain_x, num_fft)\n",
    "gtest_ps = get_ps_array(gtest_x, num_fft)\n",
    "gtrain_msf_list, gtrain_variance_list = frequency_features_extractor(gtrain_ps, f)\n",
    "gtest_msf_list, gtest_variance_list = frequency_features_extractor(gtest_ps, f)\n",
    "\n",
    "otrain_ps = get_ps_array(otrain_x, num_fft)\n",
    "otest_ps = get_ps_array(otest_x, num_fft)\n",
    "otrain_msf_list, otrain_variance_list = frequency_features_extractor(otrain_ps, f)\n",
    "otest_msf_list, otest_variance_list = frequency_features_extractor(otest_ps, f)\n",
    "\n",
    "# obtain wavelet feature\n",
    "gtrain_wp_data = wavelet_alternation(gtrain_x)\n",
    "gtest_wp_data = wavelet_alternation(gtest_x)\n",
    "\n",
    "otrain_wp_data = wavelet_alternation(otrain_x)\n",
    "otest_wp_data = wavelet_alternation(otest_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(wp_data,means_list,rms_list,waveform_facs_list,clearance_facs_list,msf_list,variance_list):\n",
    "    data_x = pd.DataFrame(\n",
    "        wp_data,\n",
    "        columns=[\n",
    "            'band 1 energy',\n",
    "            'band 2 energy',\n",
    "            'band 3 energy',\n",
    "            'band 4 energy',\n",
    "            'band 5 energy',\n",
    "            'band 6 energy',\n",
    "            'band 7 energy',\n",
    "            'band 8 energy'])\n",
    "    data_x['mean'] = means_list\n",
    "    data_x['rms'] = rms_list\n",
    "    data_x['waveform factor'] = waveform_facs_list\n",
    "    data_x['clearance factor '] = clearance_facs_list\n",
    "    data_x['msf'] = msf_list\n",
    "    data_x['Power spectrum variance'] = variance_list\n",
    "    \n",
    "    return data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtrain_x = create_df(gtrain_wp_data,gtrain_means_list,gtrain_rms_list,gtrain_waveform_facs_list,gtrain_clearance_facs_list,gtrain_msf_list,gtrain_variance_list)\n",
    "gtest_x = create_df(gtest_wp_data,gtest_means_list,gtest_rms_list,gtest_waveform_facs_list,gtest_clearance_facs_list,gtest_msf_list,gtest_variance_list)\n",
    "\n",
    "otrain_x = create_df(otrain_wp_data,otrain_means_list,otrain_rms_list,otrain_waveform_facs_list,otrain_clearance_facs_list,otrain_msf_list,otrain_variance_list)\n",
    "otest_x = create_df(otest_wp_data,otest_means_list,otest_rms_list,otest_waveform_facs_list,otest_clearance_facs_list,otest_msf_list,otest_variance_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率 1.0\n",
      "测试集准确率 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常       1.00      1.00      1.00       342\n",
      "          异常       1.00      1.00      1.00       366\n",
      "\n",
      "    accuracy                           1.00       708\n",
      "   macro avg       1.00      1.00      1.00       708\n",
      "weighted avg       1.00      1.00      1.00       708\n",
      "\n",
      "逻辑回归模型在生成数据集的AUC指标： 1.0\n"
     ]
    }
   ],
   "source": [
    "transfer = StandardScaler()\n",
    "x_train = transfer.fit_transform(gtrain_x)\n",
    "x_test = transfer.transform(gtest_x)\n",
    "y_train = gtrain_y \n",
    "y_test = gtest_y\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(x_train, y_train)\n",
    "pre_y_log = model_log.predict(x_test)\n",
    "# evaluate model \n",
    "print(\"训练集准确率\",model_log.score(x_train, y_train))\n",
    "print(\"测试集准确率\",model_log.score(x_test, y_test))\n",
    "y_pre = model_log.predict(x_test)\n",
    "print(classification_report(y_test, y_pre,labels = (0,1),target_names=(\"正常\",\"异常\")))\n",
    "print(\"逻辑回归模型在生成数据集的AUC指标：\", roc_auc_score(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率 1.0\n",
      "测试集准确率 0.9944289693593314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常       0.99      1.00      1.00       354\n",
      "          异常       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       1.00      0.80      0.87       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "逻辑回归模型在原数据集的AUC指标： 0.8\n"
     ]
    }
   ],
   "source": [
    "transfer = StandardScaler()\n",
    "x_train = transfer.fit_transform(otrain_x)\n",
    "x_test = transfer.transform(otest_x)\n",
    "y_train = otrain_y\n",
    "y_test = otest_y\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(x_train, y_train)\n",
    "pre_y_log = model_log.predict(x_test)\n",
    "# evaluate model \n",
    "print(\"训练集准确率\",model_log.score(x_train, y_train))\n",
    "print(\"测试集准确率\",model_log.score(x_test, y_test))\n",
    "y_pre = model_log.predict(x_test)\n",
    "print(classification_report(y_test, y_pre,labels = (0,1),target_names=(\"正常\",\"异常\")))\n",
    "print(\"逻辑回归模型在原数据集的AUC指标：\", roc_auc_score(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率 1.0\n",
      "测试集准确率 0.9916434540389972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常       0.99      1.00      1.00       354\n",
      "          异常       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.87      0.80      0.83       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "决策树模型在原数据集的的AUC指标： 0.798587570621469\n"
     ]
    }
   ],
   "source": [
    "x_train = otrain_x\n",
    "x_test = otest_x\n",
    "y_train = otrain_y\n",
    "y_test = otest_y\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(x_train, y_train)\n",
    "# evaluate model \n",
    "print(\"训练集准确率\",model_tree.score(x_train, y_train))\n",
    "print(\"测试集准确率\",model_tree.score(x_test, y_test))\n",
    "y_pre = model_tree.predict(x_test)\n",
    "print(classification_report(y_test, y_pre,labels = (0,1),target_names=(\"正常\",\"异常\")))\n",
    "print(\"决策树模型在原数据集的的AUC指标：\", roc_auc_score(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率 1.0\n",
      "测试集准确率 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常       1.00      1.00      1.00       342\n",
      "          异常       1.00      1.00      1.00       366\n",
      "\n",
      "    accuracy                           1.00       708\n",
      "   macro avg       1.00      1.00      1.00       708\n",
      "weighted avg       1.00      1.00      1.00       708\n",
      "\n",
      "决策树模型在生成数据集的的AUC指标： 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train = gtrain_x\n",
    "x_test = gtest_x\n",
    "y_train = gtrain_y\n",
    "y_test = gtest_y\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(x_train, y_train)\n",
    "# evaluate model \n",
    "print(\"训练集准确率\",model_tree.score(x_train, y_train))\n",
    "print(\"测试集准确率\",model_tree.score(x_test, y_test))\n",
    "y_pre = model_tree.predict(x_test)\n",
    "print(classification_report(y_test, y_pre,labels = (0,1),target_names=(\"正常\",\"异常\")))\n",
    "print(\"决策树模型在生成数据集的的AUC指标：\", roc_auc_score(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率 0.9888268156424581\n",
      "测试集准确率 0.9916434540389972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常       0.99      1.00      1.00       354\n",
      "          异常       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.99       359\n",
      "   macro avg       0.87      0.80      0.83       359\n",
      "weighted avg       0.99      0.99      0.99       359\n",
      "\n",
      "svm模型在原数据集的AUC指标： 0.798587570621469\n"
     ]
    }
   ],
   "source": [
    "x_train = otrain_x\n",
    "x_test = otest_x\n",
    "y_train = otrain_y\n",
    "y_test = otest_y\n",
    "model_svm = SVC(class_weight=\"balanced\") \n",
    "model_svm.fit(x_train,y_train)\n",
    "# evaluate model \n",
    "print(\"训练集准确率\",model_svm.score(x_train, y_train))\n",
    "print(\"测试集准确率\",model_svm.score(x_test, y_test))\n",
    "y_pre = model_svm.predict(x_test) \n",
    "print(classification_report(y_test, y_pre,labels = (0,1),target_names=(\"正常\",\"异常\")))\n",
    "print(\"svm模型在原数据集的AUC指标：\", roc_auc_score(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率 0.9198868991517436\n",
      "测试集准确率 0.9011299435028248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常       0.84      0.98      0.91       342\n",
      "          异常       0.98      0.83      0.90       366\n",
      "\n",
      "    accuracy                           0.90       708\n",
      "   macro avg       0.91      0.90      0.90       708\n",
      "weighted avg       0.91      0.90      0.90       708\n",
      "\n",
      "svm模型在生成数据集的AUC指标： 0.9037005081008532\n"
     ]
    }
   ],
   "source": [
    "x_train = gtrain_x\n",
    "x_test = gtest_x\n",
    "y_train = gtrain_y\n",
    "y_test = gtest_y\n",
    "model_svm = SVC(class_weight=\"balanced\")\n",
    "model_svm.fit(x_train,y_train)\n",
    "# evaluate model \n",
    "print(\"训练集准确率\",model_svm.score(x_train, y_train))\n",
    "print(\"测试集准确率\",model_svm.score(x_test, y_test))\n",
    "y_pre = model_svm.predict(x_test) \n",
    "print(classification_report(y_test, y_pre,labels = (0,1),target_names=(\"正常\",\"异常\")))\n",
    "print(\"svm模型在生成数据集的AUC指标：\", roc_auc_score(y_test, y_pre))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
